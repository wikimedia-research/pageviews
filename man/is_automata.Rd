% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/filter.R
\name{is_automata}
\alias{is_automata}
\title{identify non-webcrawler automated traffic}
\usage{
is_automata(user_agents)
}
\arguments{
\item{user_agents}{a vector of user agents, which can be retrieved with
\code{\link{read_sampled_log}}.}
}
\value{
a boolean vector identifying whether the user agent at the equivalent indices
in the input vector matched that of an automated service or not.
}
\description{
Not all automated traffic is from a webcrawler - much is from people running HTTP libraries
in a particularly stupid, selfish and lazy fashion (if you're reading this and you've ever had a service
making requests with the user agent "Twisted PageGetter": this means you). \code{is_automata} identifies
this class of traffic.
}
\seealso{
\code{\link{read_sampled_log}} for retrieving user agents, and
\code{\link{is_automata}} for identifying non-crawler automata.
}

